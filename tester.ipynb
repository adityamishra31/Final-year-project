{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from iBCM_Python import *\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.naive_bayes import MultinomialNB as NB\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from run_iBCM import iBCM, iBCM_verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file converted to .dat format successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_csv_to_spmf(input_file, output_file, format_type):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(input_file, header=None)\n",
    "\n",
    "    # Convert to .dat format\n",
    "    if format_type == 'dat':\n",
    "        with open(output_file, 'w') as f:\n",
    "            for index, row in df.iterrows():\n",
    "                items = row.dropna().astype(str).tolist()\n",
    "                transaction = ' '.join(items)\n",
    "                f.write(transaction + '\\n')\n",
    "        print(\"CSV file converted to .dat format successfully!\")\n",
    "\n",
    "    # Convert to .lab format\n",
    "    elif format_type == 'lab':\n",
    "        with open(output_file, 'w') as f:\n",
    "            for index, row in df.iterrows():\n",
    "                sequence = row.dropna().astype(str).tolist()\n",
    "                labels = ' '.join(sequence)\n",
    "                f.write(labels + '\\n')\n",
    "        print(\"CSV file converted to .lab format successfully!\")\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid format type. Please choose 'dat' or 'lab'.\")\n",
    "\n",
    "# Usage example:\n",
    "data=convert_csv_to_spmf('sampledata/input.csv', 'output.dat', 'dat')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels: 1638\n",
      "Skipped\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "no_folds = 3  # You can adjust the number of folds as desired\n",
    "no_win = 1\n",
    "reduce_feature_space = True\n",
    "name_result_file = 'results_iBCM_Python.csv'\n",
    "classifiers = [('Random forest', RF(n_estimators=100))]  # Update with the appropriate classifier\n",
    "np.random.seed(42)\n",
    "write_results = True\n",
    "support = 0.1\n",
    "dataset = 'alice'\n",
    "\n",
    "try:\n",
    "    run_iBCM(dataset, support, no_folds, no_win)\n",
    "except:\n",
    "    print('Skipped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#labels: 7\n",
      "\n",
      "Fold  1 / 2\n",
      "aslbu_training_fold_0_support_0.1.csv\n",
      "\n",
      "Running iBCM training\n",
      "\n",
      "**********************\n",
      "Final stats: \n",
      "Label  191  has  1249  constraints\n",
      "Label  195  has  2096  constraints\n",
      "Label  199  has  585  constraints\n",
      "Label  203  has  4671  constraints\n",
      "Label  209  has  583  constraints\n",
      "Label  210  has  668  constraints\n",
      "Label  218  has  3827  constraints\n",
      "\n",
      "Total #constraints:  10239\n",
      "Joint features: 33\n",
      "Begin size:  10206\n",
      "Remove size (Succession removal):  5895\n",
      "Remove size (Chain/Alternate removal):  8\n",
      "Remove size (Unary removal):  4\n",
      "End size:  4299\n",
      "Final total #constraints:  4299\n",
      "\n",
      "Running iBCM labelling  aslbu_training_fold_0_support_0.1.csv  for ( 4299  constraints)\n",
      "\n",
      "Running iBCM labelling  aslbu_test_fold_0_support_0.1.csv  for ( 4299  constraints)\n",
      "\n",
      "Fold  2 / 2\n",
      "aslbu_training_fold_1_support_0.1.csv\n",
      "\n",
      "Running iBCM training\n",
      "\n",
      "**********************\n",
      "Final stats: \n",
      "Label  191  has  349  constraints\n",
      "Label  195  has  780  constraints\n",
      "Label  199  has  900  constraints\n",
      "Label  203  has  1407  constraints\n",
      "Label  209  has  159  constraints\n",
      "Label  210  has  656  constraints\n",
      "Label  218  has  1831  constraints\n",
      "\n",
      "Total #constraints:  4360\n",
      "Joint features: 15\n",
      "Begin size:  4345\n",
      "Remove size (Succession removal):  2511\n",
      "Remove size (Chain/Alternate removal):  2\n",
      "Remove size (Unary removal):  2\n",
      "End size:  1830\n",
      "Final total #constraints:  1830\n",
      "\n",
      "Running iBCM labelling  aslbu_training_fold_1_support_0.1.csv  for ( 1830  constraints)\n",
      "\n",
      "Running iBCM labelling  aslbu_test_fold_1_support_0.1.csv  for ( 1830  constraints)\n",
      "Classifier  Random forest\n",
      "RandomForestClassifier()\n",
      "RandomForestClassifier()\n",
      "Avg. acc.: 0.5141509433962264\n",
      "Avg. AUC.: 0.7429548258390559\n",
      "Avg. #features.: 3064.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from joblib import dump as joblib_dump\n",
    "\n",
    "# Define the variables\n",
    "no_folds = 2\n",
    "no_win = 1\n",
    "reduce_feature_space = True\n",
    "name_result_file = 'results_iBCM_Python.csv'\n",
    "classifiers = [('Random forest', RF(n_estimators=100))]\n",
    "np.random.seed(42)\n",
    "write_results = True\n",
    "support = 0.1\n",
    "dataset = 'aslbu'\n",
    "# Call the run_iBCM function\n",
    "run_iBCM(dataset, support, no_folds, no_win)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ritikkumarsingh/miniconda3/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but RandomForestClassifier is expecting 1830 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[39m=\u001b[39m load_model()\n\u001b[1;32m     15\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m [[\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m10\u001b[39m]]\n\u001b[0;32m---> 16\u001b[0m predict_label(model,\u001b[39minput\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mpredict_label\u001b[0;34m(model, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_label\u001b[39m(model, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     label \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m label\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    800\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 820\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[1;32m    822\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    823\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    860\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    861\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    864\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    865\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    603\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 10 features, but RandomForestClassifier is expecting 1830 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "def load_model():\n",
    "    model = joblib.load(r'models/Random forest_aslbu_.joblib')\n",
    "    return model\n",
    "\n",
    "# Predict the label\n",
    "def predict_label(model, input):\n",
    "    label = model.predict(input)\n",
    "    return label\n",
    "\n",
    "# Usage example:\n",
    "model = load_model()\n",
    "input = [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]\n",
    "predict_label(model,input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
